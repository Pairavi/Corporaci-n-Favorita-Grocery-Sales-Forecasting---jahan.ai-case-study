{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7391,"databundleVersionId":44328,"sourceType":"competition"}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.682275Z","iopub.status.idle":"2025-01-30T05:29:04.682667Z","shell.execute_reply":"2025-01-30T05:29:04.682517Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install py7zr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.683857Z","iopub.status.idle":"2025-01-30T05:29:04.684409Z","shell.execute_reply":"2025-01-30T05:29:04.684188Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import py7zr\n\nfor dirname, _, filenames in os.walk('/kaggle/input/favorita-grocery-sales-forecasting'):\n    for filename in filenames:\n        archive = py7zr.SevenZipFile(os.path.join(dirname, filename), mode='r')\n        archive.extractall(path=\"/kaggle/working\")\n        archive.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.685390Z","iopub.status.idle":"2025-01-30T05:29:04.685887Z","shell.execute_reply":"2025-01-30T05:29:04.685662Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from subprocess import check_output\n\nprint(check_output([\"ls\", \"../working\"]).decode(\"utf8\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.687097Z","iopub.status.idle":"2025-01-30T05:29:04.687593Z","shell.execute_reply":"2025-01-30T05:29:04.687380Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"holiday = pd.read_csv(\"../working/holidays_events.csv\", parse_dates=['date'])\nitems = pd.read_csv(\"../working/items.csv\")\noil = pd.read_csv(\"../working/oil.csv\", parse_dates=['date'])\nstores = pd.read_csv(\"../working/stores.csv\")\n\ntrain = pd.read_csv(\"../working/train.csv\")\ntransactions = pd.read_csv(\"../working/transactions.csv\", parse_dates=['date'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.688677Z","iopub.status.idle":"2025-01-30T05:29:04.689205Z","shell.execute_reply":"2025-01-30T05:29:04.688970Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test = pd.read_csv(\"../working/test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.690482Z","iopub.status.idle":"2025-01-30T05:29:04.690979Z","shell.execute_reply":"2025-01-30T05:29:04.690758Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.691992Z","iopub.status.idle":"2025-01-30T05:29:04.692497Z","shell.execute_reply":"2025-01-30T05:29:04.692291Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test.tail()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.693470Z","iopub.status.idle":"2025-01-30T05:29:04.693954Z","shell.execute_reply":"2025-01-30T05:29:04.693735Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train[\"date\"] = pd.to_datetime(train[\"date\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.694930Z","iopub.status.idle":"2025-01-30T05:29:04.695442Z","shell.execute_reply":"2025-01-30T05:29:04.695232Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test[\"date\"] = pd.to_datetime(test[\"date\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.696548Z","iopub.status.idle":"2025-01-30T05:29:04.697078Z","shell.execute_reply":"2025-01-30T05:29:04.696816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"start_date = pd.to_datetime(\"2016-04-16\")\nend_date = start_date + pd.DateOffset(months=1)\n\n# Remote time that earthqua happen and 1 month after that \ntrain = train[~((train['date'] >= start_date) & (train['date'] <= end_date))]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.698488Z","iopub.status.idle":"2025-01-30T05:29:04.698990Z","shell.execute_reply":"2025-01-30T05:29:04.698761Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.699829Z","iopub.status.idle":"2025-01-30T05:29:04.700335Z","shell.execute_reply":"2025-01-30T05:29:04.700125Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train['date'] = pd.to_datetime(train['date'])\ntrain_filtered = train[train['date'] > '2017-01-01']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.701273Z","iopub.status.idle":"2025-01-30T05:29:04.701765Z","shell.execute_reply":"2025-01-30T05:29:04.701558Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def optimize_for_timeseries(df):\n    # Convert 'date' to datetime\n    df['date'] = pd.to_datetime(df['date'])\n\n    # Extract time-related features\n    df['year'] = df['date'].dt.year\n    df['month'] = df['date'].dt.month\n    df['day'] = df['date'].dt.day\n    df['weekday'] = df['date'].dt.weekday\n    df['quarter'] = df['date'].dt.quarter\n    del df['date']\n\n    df['id'] = df['id'].astype(np.int32)\n    df['store_nbr'] = df['store_nbr'].astype(np.int8)\n    df['item_nbr'] = df['item_nbr'].astype(np.uint32)\n    df['unit_sales'] = df['unit_sales'].astype(np.float32)\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.703682Z","iopub.status.idle":"2025-01-30T05:29:04.704182Z","shell.execute_reply":"2025-01-30T05:29:04.703947Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = optimize_for_timeseries(train_filtered)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.707385Z","iopub.status.idle":"2025-01-30T05:29:04.707808Z","shell.execute_reply":"2025-01-30T05:29:04.707640Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test['unit_sales'] = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.708730Z","iopub.status.idle":"2025-01-30T05:29:04.709153Z","shell.execute_reply":"2025-01-30T05:29:04.708972Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.710209Z","iopub.status.idle":"2025-01-30T05:29:04.710567Z","shell.execute_reply":"2025-01-30T05:29:04.710419Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df = optimize_for_timeseries(test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.711642Z","iopub.status.idle":"2025-01-30T05:29:04.712012Z","shell.execute_reply":"2025-01-30T05:29:04.711871Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.713380Z","iopub.status.idle":"2025-01-30T05:29:04.713748Z","shell.execute_reply":"2025-01-30T05:29:04.713602Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.714974Z","iopub.status.idle":"2025-01-30T05:29:04.715438Z","shell.execute_reply":"2025-01-30T05:29:04.715287Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df[\"onpromotion\"].fillna(-1, inplace=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.716552Z","iopub.status.idle":"2025-01-30T05:29:04.716917Z","shell.execute_reply":"2025-01-30T05:29:04.716776Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Filter data after 2016\n\n# Check for missing values in the filtered data\ntrain_df.isnull().sum()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.717707Z","iopub.status.idle":"2025-01-30T05:29:04.718230Z","shell.execute_reply":"2025-01-30T05:29:04.717932Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"holiday = holiday.loc[(holiday['transferred'] == False) & (holiday['type'] != 'Work Day')]\nholiday = holiday.drop(columns=['transferred'])\n\nholiday['type'] = holiday['type'].replace({\n    'Holiday': 1,\n    'Event': 2,\n    'Additional': 3,\n    'Transfer': 4,\n    'Bridge': 5\n}).fillna(0).astype(np.int8) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.719609Z","iopub.status.idle":"2025-01-30T05:29:04.720000Z","shell.execute_reply":"2025-01-30T05:29:04.719840Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"holiday['date'] = pd.to_datetime(holiday['date'])\n\nholiday['year'] = pd.to_datetime(holiday['date']).dt.year.astype(np.uint16)  \nholiday['month'] = pd.to_datetime(holiday['date']).dt.month.astype(np.uint8)  \nholiday['day'] = pd.to_datetime(holiday['date']).dt.day.astype(np.uint8) \n\ndel holiday['date']  \ndel holiday['description']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.721817Z","iopub.status.idle":"2025-01-30T05:29:04.722366Z","shell.execute_reply":"2025-01-30T05:29:04.722148Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = train_df.merge(\n    holiday[['day', 'month', 'year', 'type', 'locale']],\n    on=['day', 'month', 'year'],\n    how='left'\n);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.723488Z","iopub.status.idle":"2025-01-30T05:29:04.724013Z","shell.execute_reply":"2025-01-30T05:29:04.723784Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df = test_df.merge(\n    holiday[['day', 'month', 'year', 'type', 'locale']],\n    on=['day', 'month', 'year'],\n    how='left'\n);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.725274Z","iopub.status.idle":"2025-01-30T05:29:04.725699Z","shell.execute_reply":"2025-01-30T05:29:04.725535Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.726695Z","iopub.status.idle":"2025-01-30T05:29:04.727211Z","shell.execute_reply":"2025-01-30T05:29:04.726976Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['is_holiday'] = train_df['type'].notna().astype(np.int8);\ntest_df['is_holiday'] = test_df['type'].notna().astype(np.int8);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.728129Z","iopub.status.idle":"2025-01-30T05:29:04.728605Z","shell.execute_reply":"2025-01-30T05:29:04.728401Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.729977Z","iopub.status.idle":"2025-01-30T05:29:04.730477Z","shell.execute_reply":"2025-01-30T05:29:04.730267Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.drop(['type', 'locale'], axis=1, inplace=True)\ntest_df.drop(['type', 'locale'], axis=1, inplace=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.731297Z","iopub.status.idle":"2025-01-30T05:29:04.731781Z","shell.execute_reply":"2025-01-30T05:29:04.731557Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = train_df.merge(items[['item_nbr', 'family', 'class', 'perishable']], on='item_nbr', how='left')\ntest_df = test_df.merge(items[['item_nbr', 'family', 'class', 'perishable']], on='item_nbr', how='left')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.732786Z","iopub.status.idle":"2025-01-30T05:29:04.733304Z","shell.execute_reply":"2025-01-30T05:29:04.733090Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"oil['date'] = pd.to_datetime(oil['date'])\n\noil['year'] = pd.to_datetime(oil['date']).dt.year.astype(np.uint16)  \noil['month'] = pd.to_datetime(oil['date']).dt.month.astype(np.uint8)  \noil['day'] = pd.to_datetime(oil['date']).dt.day.astype(np.uint8) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.734290Z","iopub.status.idle":"2025-01-30T05:29:04.735765Z","shell.execute_reply":"2025-01-30T05:29:04.734558Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"oil['dcoilwtico'] = oil['dcoilwtico'].astype(np.float32);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.736853Z","iopub.status.idle":"2025-01-30T05:29:04.737402Z","shell.execute_reply":"2025-01-30T05:29:04.737172Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"oil\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.738359Z","iopub.status.idle":"2025-01-30T05:29:04.738861Z","shell.execute_reply":"2025-01-30T05:29:04.738636Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(oil.dtypes);\n# train_df = train_df.merge(oil[['dcoilwtico']], on=['year', 'month', 'day'], how='left')\n# test_df = test_df.merge(oil[['dcoilwtico']], on=['year', 'month', 'day'], how='left')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.739695Z","iopub.status.idle":"2025-01-30T05:29:04.740219Z","shell.execute_reply":"2025-01-30T05:29:04.739975Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.741595Z","iopub.status.idle":"2025-01-30T05:29:04.742111Z","shell.execute_reply":"2025-01-30T05:29:04.741882Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = train_df.merge(stores, on='store_nbr', how='left')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.743012Z","iopub.status.idle":"2025-01-30T05:29:04.743515Z","shell.execute_reply":"2025-01-30T05:29:04.743307Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df = test_df.merge(stores, on='store_nbr', how='left')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.744541Z","iopub.status.idle":"2025-01-30T05:29:04.745023Z","shell.execute_reply":"2025-01-30T05:29:04.744805Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.746084Z","iopub.status.idle":"2025-01-30T05:29:04.746557Z","shell.execute_reply":"2025-01-30T05:29:04.746353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.747772Z","iopub.status.idle":"2025-01-30T05:29:04.748289Z","shell.execute_reply":"2025-01-30T05:29:04.748077Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\n\n\n\n# Combine train and test data to handle features (to avoid leakage)\nall_data = pd.concat([train_df, test_df], ignore_index=True)\n\n# Convert date parts into a single datetime column for both train and test\nall_data[\"ds\"] = pd.to_datetime(all_data[[\"year\", \"month\", \"day\"]])\n\n# Encode categorical features (store_nbr, item_nbr) as integers (use LabelEncoder or similar)\nall_data['store_nbr'] = all_data['store_nbr'].astype(\"category\").cat.codes\nall_data['item_nbr'] = all_data['item_nbr'].astype(\"category\").cat.codes\n\n# Define feature columns\nfeatures = [\"store_nbr\", \"item_nbr\", \"onpromotion\", \"is_holiday\", \"year\", \"month\", \"weekday\", \"quarter\"]\n\n# Extract the target variable and features\nX = all_data[features]\ny = all_data[\"unit_sales\"]\n\n# Split into train and test sets based on the original data split\ntrain_data = all_data[:len(train_df)]\ntest_data = all_data[len(train_df):]\n\n# Separate train and test features and target\nX_train = train_data[features]\ny_train = train_data[\"unit_sales\"]\nX_test = test_data[features]\ny_test = test_data[\"unit_sales\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.749306Z","iopub.status.idle":"2025-01-30T05:29:04.749771Z","shell.execute_reply":"2025-01-30T05:29:04.749564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def normalized_weighted_rmsle(y_true, y_pred, weights):\n\n#     log_y_true = np.log1p(y_true)\n#     log_y_pred = np.log1p(y_pred)\n\n#     log_errors = log_y_pred - log_y_true\n    \n#     squared_log_errors = log_errors ** 2\n    \n#     weighted_squared_log_errors = weights * squared_log_errors\n    \n#     weighted_error_sum = np.sum(weighted_squared_log_errors)\n#     total_weights = np.sum(weights)\n    \n#     normalized_weighted_mean = weighted_error_sum / total_weights\n#     return np.sqrt(normalized_weighted_mean)\n\n# weights_train = np.where(X_train['perishable'] == 1, 1.25, 1)\n# weights_test = np.where(X_test['perishable'] == 1, 1.25, 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.750753Z","iopub.status.idle":"2025-01-30T05:29:04.751254Z","shell.execute_reply":"2025-01-30T05:29:04.751022Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom lightgbm import LGBMRegressor\nfrom sklearn.metrics import mean_squared_error\n\n# Convert date columns into a single datetime column\ntrain_df[\"ds\"] = pd.to_datetime(train_df[[\"year\", \"month\", \"day\"]])\n\n# Encode categorical features\nlabel_encoders = {}\nfor col in [\"store_nbr\", \"item_nbr\", \"city\", \"state\", \"family\", \"type\", \"cluster\"]:\n    le = LabelEncoder()\n    train_df[col] = le.fit_transform(train_df[col])\n    label_encoders[col] = le  # Store encoder for potential inverse transformation\n\n# Load perishable weights from items.csv\nitems_df = pd.read_csv(\"items.csv\")\nitems_df[\"weight\"] = np.where(items_df[\"perishable\"] == 1, 1.25, 1.00)\n\n# Merge perishable weights with train data\ntrain_df = train_df.merge(items_df[[\"item_nbr\", \"weight\"]], on=\"item_nbr\", how=\"left\")\n\n# Define feature columns\nfeatures = [\n    \"store_nbr\", \"item_nbr\", \"onpromotion\", \"is_holiday\", \n    \"year\", \"month\", \"weekday\", \"quarter\", \"perishable\", \"cluster\"\n]\n\n# Extract features and target variable\nX = train_df[features]\ny = train_df[\"unit_sales\"]\nweights = train_df[\"weight\"]  # Store weights\n\n# Split into training and validation sets (80-20 split)\nX_train, X_val, y_train, y_val, w_train, w_val = train_test_split(\n    X, y, weights, test_size=0.2, random_state=42\n)\n\n# Use LightGBM (efficient alternative to RF)\nmodel = LGBMRegressor(n_estimators=50, max_depth=10, learning_rate=0.05, random_state=42)\nmodel.fit(X_train, y_train, sample_weight=w_train)\n\n# Predict on validation set\ny_pred = model.predict(X_val)\n\n# Compute NWRMSLE\ndef nwrmsle(y_true, y_pred, weights):\n    log_true = np.log1p(y_true)\n    log_pred = np.log1p(y_pred)\n    weighted_error = weights * (log_pred - log_true) ** 2\n    return np.sqrt(weighted_error.sum() / weights.sum())\n\n# Print NWRMSLE score\nnwrmsle_score = nwrmsle(y_val, y_pred, w_val)\nprint(f\"Validation NWRMSLE: {nwrmsle_score:.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T05:29:04.752280Z","iopub.status.idle":"2025-01-30T05:29:04.752805Z","shell.execute_reply":"2025-01-30T05:29:04.752564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert date columns into a single datetime column for test data\ntest_df[\"ds\"] = pd.to_datetime(test_df[[\"year\", \"month\", \"day\"]])\n\n# Encode categorical features for test data\nfor col in [\"store_nbr\", \"item_nbr\", \"city\", \"state\", \"family\", \"type\", \"cluster\"]:\n    test_df[col] = label_encoders[col].transform(test_df[col])  # Use stored encoders\n\n# Merge perishable weights for test data\ntest_df = test_df.merge(items_df[[\"item_nbr\", \"weight\"]], on=\"item_nbr\", how=\"left\")\n\n# Define feature columns (same as used for training)\nfeatures = [\n    \"store_nbr\", \"item_nbr\", \"onpromotion\", \"is_holiday\", \n    \"year\", \"month\", \"weekday\", \"quarter\", \"perishable\", \"cluster\"\n]\n\n# Extract features from test data\nX_test = test_df[features]\n\n# Predict on test data\ny_test_pred = model.predict(X_test)\n\n# Add predictions to test_df\ntest_df[\"unit_sales\"] = y_test_pred\n\nsubmission_df = test_df[[\"id\", \"unit_sales\"]]\n\n# Save the predictions to a CSV file\nsubmission_df.to_csv(\"submission.csv\", index=False)\n\n# Print the first few rows of the submission (optional)\nprint(submission_df.head())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}